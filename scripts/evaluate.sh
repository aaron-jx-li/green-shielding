#!/bin/bash

#SBATCH -c 20        # Number of cores (-c)
#SBATCH -t 3-00:00     # Runtime in D-HH:MM, minimum of 10 minutes
#SBATCH -p jsteinhardt  # Partition to submit to
#SBATCH --mem=10000
#SBATCH -o ./%j.out # File to which STDOUT will be written, %j inserts jobid
#SBATCH -e ./%j.err # File to which STDERR will be written, %j inserts jobid

export OPENAI_API_KEY=''

# prompt the target model to get model responses
python ../normalization/inference.py --input_path ../results/HCM-3k/responses_gpt-4.1-mini.json --output_path ../results/HCM-3k/NEW_RESPONSE_FILE_NAME.json --model gpt-4.1-mini --col_name raw_input 

# evaluate the model responses against the truth generated by multiple strong LLM judges
python ../open_eval/evaluate.py --input_path ../results/HCM-3k/NEW_RESPONSE_FILE_NAME.json --pxhx_path ../results/HCM-3k/merged_truth.json  --output_path ../results/HCM-3k/NEW_EVAL_FILE_NAME.json --col_name model_response